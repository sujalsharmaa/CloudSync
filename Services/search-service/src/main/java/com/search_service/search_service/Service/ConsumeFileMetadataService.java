package com.search_service.search_service.Service;

import com.fasterxml.jackson.databind.ObjectMapper;
import com.search_service.search_service.Dto.SavedFileDto;
import com.search_service.search_service.Model.FileMetadata;
import com.search_service.search_service.Repository.FileMetadataRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.data.redis.core.StringRedisTemplate;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Service;
import org.springframework.data.redis.core.RedisTemplate; // <-- Now correctly used

import java.io.IOException;
import java.util.Date;
import java.util.Optional;
import java.time.Duration; // <-- New import

@Slf4j
@Service
public class ConsumeFileMetadataService {

    private final ObjectMapper objectMapper;
    private final FileMetadataRepository fileMetadataRepository;
    private final StringRedisTemplate redisTemplate; // Use StringRedisTemplate for string values
    private final SearchService searchService; // <-- 1. Inject SearchService
    private static final String CONFIRMATION_KEY_PREFIX = "metadata_processed:";

    @Autowired
    public ConsumeFileMetadataService(ObjectMapper objectMapper,
                                      FileMetadataRepository fileMetadataRepository,
                                      StringRedisTemplate redisTemplate,
                                      SearchService searchService // <-- 1. Inject SearchService
    ) {
        this.objectMapper = objectMapper;
        this.fileMetadataRepository = fileMetadataRepository;
        this.redisTemplate = redisTemplate;
        this.searchService = searchService; // <-- 1. Inject SearchService
    }

    /**
     * Listens to the Kafka topic for new file metadata and saves it to Elasticsearch.
     * Also signals completion via Redis and invalidates relevant caches.
     *
     * @param message The JSON string message containing file metadata.
     */
    @KafkaListener(topics = "file-metadata-search", groupId = "rag-pipeline-group")
    public void listen(String message) {
        try {
            // 1. Deserialize the message into FileMetadata object
            FileMetadata fileMetadata = objectMapper.readValue(message, FileMetadata.class);
            String fileName = fileMetadata.getFileName();
            String userId = fileMetadata.getUserId(); // Extract userId

            log.info("Received metadata for file: {}", fileName);

            // Optional: Check if metadata already exists (e.g., based on userId and fileName)
            // This might prevent duplicates if messages are reprocessed.
            // Example: Optional<FileMetadata> existing = fileMetadataRepository.findByUserIdAndFileName(userId, fileName);
            // if (existing.isPresent()) { log.warn(...); return; }

            // Ensure processedAt is set if not already present
            if (fileMetadata.getProcessedAt() == null) {
                fileMetadata.setProcessedAt(new Date());
            }

            // 2. Save the FileMetadata object to Elasticsearch
            fileMetadataRepository.save(fileMetadata);
            // After saving, fileMetadata will have its ID populated if generated by Elasticsearch
            String fileId = fileMetadata.getId();
            log.info("Successfully saved metadata for file: {} with ID: {}", fileName, fileId);

            // --- 3. Send Confirmation Signal to UploadService via Redis ---
            // Construct a unique key using user ID and file name
            String confirmationKey = CONFIRMATION_KEY_PREFIX + userId + ":" + fileName;

            // Set the key with the generated file ID as the value and add an expiration
            redisTemplate.opsForValue().set(confirmationKey, fileId, Duration.ofSeconds(60)); // Increased TTL slightly
            log.info("Set Redis confirmation key: {} with value (fileId): {}", confirmationKey, fileId);
            // -----------------------------------------------------------


            // --- 4. Invalidate User's File Cache ---
            if (userId != null && !userId.isEmpty()) {
                log.info("Invalidating file cache for user: {}", userId);
                searchService.evictUserFileCache(userId); // <-- Call the cache eviction method
            } else {
                log.warn("Cannot invalidate cache for file {} as userId is missing.", fileName);
            }
            // ----------------------------------------


        } catch (IOException e) {
            log.error("Error deserializing message or saving metadata: {}", e.getMessage(), e);
            // Handle error appropriately (e.g., send to dead-letter queue)
        } catch (Exception e) {
            log.error("An unexpected error occurred during metadata processing: {}", e.getMessage(), e);
            // Handle unexpected errors
        }
    }
}